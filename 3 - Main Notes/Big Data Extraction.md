
2024-11-06 05:03

Status: #InProgress

Tags: [[big data]] 

# Big Data Extraction

Data extraction is process of getting data from a source for further processing, storage, or analysis. Data is typically *crawled* through to get any information out of it from sources such as databases or documents.

Data extraction basically refers to the process of procuring data from a given source and then moving it to a new context.

## Extract/Transform/Load (ETL)

- Data extraction is perhaps the most crucial part of ETL. Some even call it the backbone of ETL. ETL is basically a process that that drives the data and analytics workflows.
- ETL allows organizations to bring data from different sources into a single location.

**Extraction**: Gathering data from one or more sources. This process includes locating and identifying relevant data.
**Transformation**: In this stage the data is preprocessed.
**Loading**: The preprocessed data is sent to a central repo for immediate or further analysis

## Types of Data Extractions

When it comes to data extraction, there are mainly 2 types:
1. Structured 
2. Unstructured

Data extraction happens for one of the following 3 reasons:
1. Archiving data for secure and long term storage
2. Moving data to new context (new domain, database etc)
3. Preparing it for later-stage analysis

### Structured Data

- Refers to data formatted according to standardized models making it ready for analysis.
- Structured data can be extracted using **logical data extraction**. It is broken down into
  1. Full Extraction








#### References
[[Big Data Extraction University Lecture.pdf]]